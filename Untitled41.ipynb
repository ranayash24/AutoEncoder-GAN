{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCQDw8tElCRiXnUC3HQ5rF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranayash24/AutoEncoder-GAN/blob/master/Untitled41.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC8h4gbvVFcY",
        "outputId": "c3e62d2a-4ee7-4e83-e15b-06cc3ca1c141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28\n",
        "\n",
        "import openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLETIONS_MODEL = \"gpt-4\"\n",
        "openai.api_key = (\"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\")\n",
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages = [{\"role\": \"system\", \"content\" : \"Answer the follwing question the best you can.\"},\n",
        "{\"role\": \"user\", \"content\" : \"How to configure  Flowise AI?\"}\n",
        "]\n",
        ")\n",
        "\n",
        "print(completion[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrrhpmU4VZm3",
        "outputId": "c2a11b44-0d20-4935-d7a9-d8ac9b41f6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I couldn't find any specific information about a technology, product, or service called \"Flowise AI\". It's possible that there might be a spelling mistake or confusion with the name. If it's a specific kind of software or system related to AI or Machine Learning, the configuration would generally involve settings related to its function. \n",
            "\n",
            "For instance, you might have to:\n",
            "\n",
            "1. Install the software on a server or computer.\n",
            "2. Specify the parameters or settings related to its task (like training a machine learning model).\n",
            "3. Test it to ensure that it is working correctly.\n",
            "\n",
            "If you're talking about some specific AI or ML platform or toolkit, such as TensorFlow or H2O.ai, each one will have its own unique setup and configuration process. It'd be better if you could provide more detailed information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4-0613\",\n",
        "  messages = [{\"role\": \"system\", \"content\" : \"\"\"Answer the follwing question the best you can. Prerequisites\n",
        "Ensure you have the latest version of NodeJS installed on your system to work with Flowise AI.\n",
        "Installation and Starting Flowise AI\n",
        "Install Flowise AI: Use npm to install Flowise globally on your machine with the command npm install -g flowise.\n",
        "Start Flowise AI: After installation, start the Flowise service using npx flowise start. This will run Flowise AI locally on your machine.\n",
        "Access Flowise AI: Open your web browser and go to http://localhost:3000 to access the Flowise AI platform.\n",
        "Using Docker for Deployment\n",
        "Docker Compose: Navigate to the docker directory at the root of the project, copy the .env.example file to .env, and run docker-compose up -d to start the containers. Access the platform via http://localhost:3000.\n",
        "Docker Image: Alternatively, you can build a Docker image locally and run it to start Flowise AI. Commands for building the image, running it, and stopping it are provided in the documentation.\n",
        "Development Setup\n",
        "For developers, Flowise AI organizes its codebase into three main modules:\n",
        "\n",
        "server: A Node.js backend to serve API logic.\n",
        "ui: A React frontend for the user interface.\n",
        "components: Integration components for extending functionality.\n",
        "Development Steps:\n",
        "\n",
        "Clone the Flowise AI repository.\n",
        "Navigate into the repository folder.\n",
        "Use Yarn to install all dependencies for all modules.\n",
        "Build the entire codebase.\n",
        "Start the application to access it on http://localhost:3000.\n",
        "For development purposes, use yarn dev to start a development build with hot reload enabled on code changes, accessible on http://localhost:8080.\n",
        "API Configuration\n",
        "Flowise AI offers an API for integrating its capabilities into your applications:\n",
        "\n",
        "Prediction API: Send POST requests to make predictions based on user inputs, with options to override configurations and use Short Term Memory for context management.\n",
        "Vector Upsert API: Manage vector data within your LLM applications by upserting vector information, with options for overriding configurations and specifying node IDs for targeted upserts.\n",
        "Message API: Retrieve and manage chat messages through GET and DELETE requests, with filters for session IDs, sorting, and date ranges.\n",
        "The API section provides detailed examples of how to use these endpoints with Python and JavaScript, including request bodies, configuration options, and response handling.\"\"\"},\n",
        "{\"role\": \"user\", \"content\" : \"How to configure Flowise AI?\"}\n",
        "]\n",
        ")\n",
        "\n",
        "print(completion[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAcd2lsXWgr_",
        "outputId": "e65b59e5-2b67-4115-db60-ab53d66fe5ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Firstly, ensure that you have the latest version of NodeJS installed on your system to work with Flowise AI.\n",
            "\n",
            "Installation and Starting:\n",
            "1. Install Flowise AI using npm. Run the command `npm install -g flowise` to install it globally on your machine.\n",
            "2. After installation, start the Flowise service using `npx flowise start`. Flowise AI will run locally on your machine.\n",
            "3. To access Flowise AI platform, open your web browser and go to http://localhost:3000.\n",
            "\n",
            "Now, Docker can also be used for deployment: \n",
            "1. Docker Compose: Navigate to the docker directory at the root of the project, copy the .env.example file to .env, and run `docker-compose up -d` to start the containers. Access it via http://localhost:3000.\n",
            "2. Docker Image: Alternatively, you can build a Docker image locally and run it to start Flowise AI. Commands for building the image, running it, and stopping it are provided in the documentation.\n",
            "\n",
            "\n",
            "For development setup: \n",
            "Flowise AI organizes its codebase into three main modules: server (Node.js backend), ui (React frontend), and components (Integration components).\n",
            "1. Clone the Flowise AI repository.\n",
            "2. Navigate into the repository folder.\n",
            "3. Use Yarn to install all dependencies for all modules.\n",
            "4. Build the entire codebase.\n",
            "5. Start the application to access it on http://localhost:3000. \n",
            "6. For development purposes, use `yarn dev` to start a development build with hot reload enabled on code changes, accessible on http://localhost:8080.\n",
            "\n",
            "API Configuration:\n",
            "Flowise AI offers APIs like Prediction API, Vector Upsert API, and Message API, which are used for integrating its functionalities into applications. Configuration options and detailed examples of request bodies and response handling are provided in these APIs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai\n",
        "\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "SbiDMS35YTDt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "50e3d658-bf98-4ef5-bb8e-128d39cf225d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.10/dist-packages/openai/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a4a244a13f9f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.10/dist-packages/openai/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7oyw0GCRyq1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = (\"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\")\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        " messages = [{\"role\": \"system\", \"content\" : \"Answer the follwing question the best you can.\"},\n",
        "{\"role\": \"user\", \"content\" : \"How to configure  Flowise AI?\"}\n",
        "]\n",
        ")\n",
        "print(completion[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "kB9Ulfv6xlc6",
        "outputId": "22bfc692-2983-47e2-a410-13a767336d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3b2fca3e32fa>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"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\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  messages = [{\"role\": \"system\", \"content\" : \"Answer the follwing question the best you can.\"},\n\u001b[1;32m      5\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"How to configure  Flowise AI?\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLETIONS_MODEL = \"gpt-4\"\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Vgn6zw_RxzqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol7zdv-zy1aj",
        "outputId": "6f2c57d4-8e3c-4c21-b0ed-854208a2033f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: OpenAI in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from OpenAI) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->OpenAI) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->OpenAI) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->OpenAI) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->OpenAI) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->OpenAI) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->OpenAI) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->OpenAI) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->OpenAI) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->OpenAI) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->OpenAI) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Authorization: Bearer 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"
      ],
      "metadata": {
        "id": "U4BGwqd8y-lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  organization='org-UiwoLLXFLBx5OneIDSG3FVDS',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1Rj-DMCRzIlK",
        "outputId": "db3815d5-1b7a-4485-e867-468d48b07fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.10/dist-packages/openai/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a0032b2c6d96>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m client = OpenAI(\n\u001b[1;32m      4\u001b[0m   \u001b[0morganization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'org-UiwoLLXFLBx5OneIDSG3FVDS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.10/dist-packages/openai/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}